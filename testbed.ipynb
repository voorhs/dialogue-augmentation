{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 615/615 [00:00<00:00, 80.3kB/s]\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 21.4MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 9.10M/9.10M [00:00<00:00, 34.0MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250002"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "len(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 300/300 [00:00<00:00, 45.1kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 670/670 [00:00<00:00, 282kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 22.3MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 50.5kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained('Shitao/RetroMAE_MSMARCO')\n",
    "len(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'500.json'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "chunk_names = [fname for fname in os.listdir('data/augmented/back-translate/') if fname.endswith('.json')]\n",
    "chunk_names[414]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyarrow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [\n",
    "    {\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Hey.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Hey, what can I do for you?\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"I'd like to visit Chicago, Il-Ord, to meet my best friend, so I need to book a plane ticket.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Okay.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Could you book me a ticket for 09/09?\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Please send me the place of origin.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"My name is Stephanie Carter.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"May I ask the date of arrival, please?\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"I'd like to arrive at 09/11.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Please send the exact location of your origin.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Of course, my origins are Dallas and Fort Worth, TX - DFW.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Do you have any other specifications?\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Yeah, I need to stop between my journey.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"I found a Hawaiian airline number 1003, which meets your criteria.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"All right, please book the tickets.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Your ticket is booked.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Thank you.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Thank you.\"\n",
    "            }\n",
    "        ],\n",
    "        \"source_dataset_name\": \"AirDialogue\",\n",
    "        \"idx_within_source\": 187590,\n",
    "        \"idx\": 0\n",
    "    },\n",
    "    {\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Hey.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Hey, what can I do for you today?\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"I'm Anthony Martinez from Charlotte, I want to go to Orlando this month to attend the summit, could you book a ticket from the CLT to MCO?\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"I'm here to help you with that.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Thank you, I want to leave for 08/13 and book my return ticket for 08/15, too.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Wait a minute.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Okay.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"There's a one-stop flight with a 100 ticket rate, which is provided by Jet Blue airlines.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Please continue.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"I booked your flight 1026.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 0,\n",
    "                \"utterance\": \"Thank you for your help.\"\n",
    "            },\n",
    "            {\n",
    "                \"speaker\": 1,\n",
    "                \"utterance\": \"Greetings, thank you for choosing our service.\"\n",
    "            }\n",
    "        ],\n",
    "        \"source_dataset_name\": \"AirDialogue\",\n",
    "        \"idx_within_source\": 285622,\n",
    "        \"idx\": 1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'MS-DC',\n",
    "    'MetaLWOZ',\n",
    "    'MULTIWOZ2_2',\n",
    "    'SGD',\n",
    "    'SimJointGEN',\n",
    "    'KETOD',\n",
    "    'FRAMES',\n",
    "    'Disambiguation',\n",
    "    'ABCD',\n",
    "    'AirDialogue',\n",
    "    'BiTOD',\n",
    "    'Taskmaster1'\n",
    "]\n",
    "\n",
    "upper_bound = 96\n",
    "\n",
    "upper_bounds = {\n",
    "    'MS-DC': min(upper_bound, 250),\n",
    "    'MetaLWOZ': min(upper_bound, 100),\n",
    "    'MULTIWOZ2_2': min(upper_bound, 75),\n",
    "    'SGD': None,\n",
    "    'SimJointGEN': upper_bound,\n",
    "    'KETOD': upper_bound,\n",
    "    'FRAMES': upper_bound,\n",
    "    'Disambiguation': min(upper_bound, 60),\n",
    "    'ABCD': upper_bound,\n",
    "    'AirDialogue': upper_bound,\n",
    "    'BiTOD': upper_bound,\n",
    "    'Taskmaster1': min(upper_bound, 200),\n",
    "}\n",
    "\n",
    "\n",
    "from random import shuffle, seed as set_seet\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from functools import partial\n",
    "from typing import Tuple, List\n",
    "from tqdm import tqdm\n",
    "from mylib.utils.data import Dialogue, ContextResponsePair\n",
    "import json\n",
    "import os\n",
    "import pyarrow as pa\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def preprocess_dialogue(\n",
    "        raw_sample,\n",
    "        tokenizer,\n",
    "        bound=None,\n",
    "        user_id=0,\n",
    "        system_id=1,\n",
    "    ):\n",
    "    \"\"\"convert single dialogue (in DialogStudio format) to list of utterances and list of corresponding speaker ids\"\"\"\n",
    "    \n",
    "    if is_empty(raw_sample) or is_too_long(raw_sample) or has_only_single_utterance(raw_sample):\n",
    "        return\n",
    "\n",
    "    utterances = []\n",
    "    speakers = []\n",
    "    \n",
    "    for turn in raw_sample:\n",
    "        for sp, item in zip([user_id, system_id], ['user utterance', 'system response']):\n",
    "            ut = turn[item]\n",
    "            if ut == '':\n",
    "                continue\n",
    "            utterances.append(ut)\n",
    "            speakers.append(sp)\n",
    "    \n",
    "    if bound is not None and any(is_above_bound(ut, tokenizer, bound) for ut in utterances):\n",
    "        # if there're any utterances with exceeding length\n",
    "        return\n",
    "    \n",
    "    return utterances, speakers\n",
    "\n",
    "\n",
    "def is_empty(dia):\n",
    "    return len(dia) == 0\n",
    "\n",
    "\n",
    "def is_too_long(dia):\n",
    "    return len(dia) > 10\n",
    "\n",
    "\n",
    "def has_only_single_utterance(dia):\n",
    "    return len(dia) == 1 and (dia[0]['user utterance'] == '' or dia[0]['system response'] == '')\n",
    "\n",
    "\n",
    "def is_above_bound(ut, tokenizer, bound):\n",
    "    return len(tokenizer(ut)['input_ids']) > bound\n",
    "\n",
    "\n",
    "def get_record_iterator(name, tokenizer, bound):\n",
    "    dataset = load_dataset('Salesforce/dialogstudio', name)['train']['log']\n",
    "    for i, raw_dia in enumerate(dataset):\n",
    "        dia = preprocess_dialogue(raw_dia, tokenizer, bound)\n",
    "        if dia is None:\n",
    "            continue\n",
    "        utterances, speakers = dia\n",
    "        dia = Dialogue(\n",
    "            utterances=utterances,\n",
    "            speakers=speakers,\n",
    "            source_dataset_name=name,\n",
    "            idx_within_source=i,\n",
    "            # idx=None\n",
    "        )\n",
    "        dct = dia.asdict()\n",
    "        dct['content'] = json.dumps(dct['content'])\n",
    "        yield pa.RecordBatch.from_pylist([dct])\n",
    "\n",
    "\n",
    "def train_test_split(data: List[Dialogue], frac=0.9, seed=0):\n",
    "    \"\"\"resulting sizes:\n",
    "    - train: `frac`\n",
    "    - test: `(1 - frac) // 2`\n",
    "    - val: `(1 - frac) // 2`\"\"\"\n",
    "    \n",
    "    set_seet(seed)\n",
    "    shuffle(data)\n",
    "\n",
    "    # assign indices after shuffling the dataset\n",
    "    for i, dia in enumerate(data):\n",
    "        dia.idx = i\n",
    "\n",
    "    n_total = len(data)\n",
    "    train_size = ceil(frac * n_total)\n",
    "    test_size = (n_total - train_size) // 2\n",
    "    val_size = n_total - train_size - test_size\n",
    "\n",
    "    res = {\n",
    "        'train': data[:train_size],\n",
    "        'test': data[train_size:train_size+test_size],\n",
    "        'val': data[train_size+test_size:]\n",
    "    }\n",
    "\n",
    "    print('dataset splits sizes:')\n",
    "    print(f'{n_total=}, {train_size=}, {test_size=}, {val_size=}')\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def make_pairs(dialogues):\n",
    "    res = []\n",
    "    for dia in tqdm(dialogues, desc='making pairs'):\n",
    "        pairs = []\n",
    "        for i in range(len(dia)-1):\n",
    "            pairs.append((dia[:i+1], dia[i+1]))\n",
    "        res.extend(pairs)\n",
    "    shuffle(res)\n",
    "    res = [ContextResponsePair(context=c, response=r, idx=i) for i, (c, r) in enumerate(res)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from collections import defaultdict\n",
    "from mylib.utils.training import seed_everything\n",
    "import itertools as it\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "seed_everything(0)\n",
    "\n",
    "# supress warnings about long sequences\n",
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
    "\n",
    "#! not the same as roberta, replace in future\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/mpnet-base')\n",
    "\n",
    "# load datasets from hugging face, parse, filter and merge into single list\n",
    "record_iterator_list = []\n",
    "for dataset_name in names:\n",
    "    iterator = get_record_iterator(dataset_name, tokenizer, upper_bounds[dataset_name])\n",
    "    record_iterator_list.append(iterator)\n",
    "\n",
    "chained_iterator = it.chain.from_iterable(record_iterator_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = iter(chained_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.RecordBatch\n",
       "content: string\n",
       "source_dataset_name: string\n",
       "idx_within_source: int64\n",
       "----\n",
       "content: [\"[{\"utterance\": \"I'd like 2 tickets to see Zoolander 2 tomorrow at Regal Meridian 16 theater in Seattle at 9:25 PM\", \"speaker\": 0}, {\"utterance\": \"Okay, your purchase of 2 tickets for Zoolander 2 is confirmed.\", \"speaker\": 1}]\"]\n",
       "source_dataset_name: [\"MS-DC\"]\n",
       "idx_within_source: [0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "\n",
    "source_dataset = ds.dataset('data-2/source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>idx_within_source</th>\n",
       "      <th>source_dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"utterance\": \"Hi, how can I help you?\", \"spe...</td>\n",
       "      <td>81664</td>\n",
       "      <td>SimJointGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{\"utterance\": \"Hi, how can I help you?\", \"spe...</td>\n",
       "      <td>81665</td>\n",
       "      <td>SimJointGEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  idx_within_source  \\\n",
       "0  [{\"utterance\": \"Hi, how can I help you?\", \"spe...              81664   \n",
       "1  [{\"utterance\": \"Hi, how can I help you?\", \"spe...              81665   \n",
       "\n",
       "  source_dataset_name  \n",
       "0         SimJointGEN  \n",
       "1         SimJointGEN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dataset.take([100500, 100501]).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'pyarrow._dataset.FileSystemDataset' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msource_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'pyarrow._dataset.FileSystemDataset' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "source_dataset.shuffle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
